{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0323ali/Machine-Learning/blob/main/CNN_road_condition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aaISabPk1HUM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzDN0MPQOhlv",
        "outputId": "c8d48bd5-8714-493c-f5d3-fb7814a29335"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-d_XWjLnO2os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=cv2.imread(\"/content/drive/MyDrive/Data_set/Data/bump/Image00060.jpg\")\n",
        "print(a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWvxDcYOOuqm",
        "outputId": "a2c8c0ee-daa6-4e24-b424-2166fc5385cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(460, 816, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Resizes all images to **400×400** pixels before feeding them into the model.\n",
        "\n",
        "2.  Loads images in batches of 32 (instead of all at once). This helps with memory efficiency and faster training.\n",
        "\n",
        "3.  Used for integer-labeled classes (e.g., 0, 1, 2, 3 instead of [0,1,0,0])."
      ],
      "metadata": {
        "id": "RLrZ7jZyF7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = ImageDataGenerator(rescale=1/255)\n",
        "train_dataset = train.flow_from_directory(\n",
        "    r'/content/drive/MyDrive/Data_set/Data',\n",
        "    target_size=(400, 400),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks2S0Ol6PMgE",
        "outputId": "a57563a9-8fc5-4801-d69f-b8894c4f82de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_dataset.class_indices)\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9n-ef9dT85f",
        "outputId": "75539f4a-9191-41c7-9849-d49a104ea8b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rddjnQ5iWC4u",
        "outputId": "8c1dbf0b-dfa0-45ca-cdc6-eadcb5b5d3a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bump': 0, 'crack': 1, 'potholes': 2, 'road': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **Convolutional Neural Network (CNN)** built using TensorFlow and Keras, designed for image classification.\n",
        "\n",
        "\n",
        "1.   **Conv2D(16, (3,3), activation='relu', input_shape=(400, 400, 3))**\n",
        "Applies 16 filters (small 3×3 matrices) to detect patterns (edges, textures).\n",
        "Uses ReLU activation to introduce non-linearity.\n",
        "input_shape=(400, 400, 3) → Expects 400×400 RGB images (3 channels for color).\n",
        "\n",
        " **MaxPool2D(2,2)**\n",
        "Reduces the spatial size by taking the maximum value in a 2×2 window.\n",
        "This helps in reducing computation and extracting important features.\n",
        "2.  **Conv2D(32, (3,3), activation='relu') → 32** filters to capture more complex features.\n",
        "\n",
        " **MaxPool2D(2,2) → Again** reduces spatial size.\n",
        "3.  **Conv2D(64, (3,3), activation='relu') → 64** filters for deeper feature extraction.\n",
        "\n",
        " **MaxPool2D(2,2) → Reduces** feature map size further.\n",
        "\n",
        "4. Converts the 2D feature maps into a 1D vector so it can be processed by dense (fully connected) layers.\n",
        "\n",
        "5.  A **dense layer** with 512 neurons and **ReLU** activation.\n",
        " This acts as a hidden layer to learn complex patterns from features.\n",
        "6. Output layer with 4 neurons (suggesting 4 classes in classification).\n",
        " Uses **Softmax activation**, which converts outputs into probabilities (summing to 1)."
      ],
      "metadata": {
        "id": "ZiA45vOT-le9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(400, 400, 3)),\n",
        "    tf.keras.layers.MaxPool2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "BM4JdtokQI7o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adam** (Adaptive Moment Estimation) is an advanced gradient descent optimization algorithm.\n",
        "\n",
        "It combines:\n",
        "1.  **Momentum-based updates** (helps in faster convergence).\n",
        "2.  **Adaptive learning rates** (adjusts learning rates for each parameter).\n",
        "\n",
        "Adam is commonly used in deep learning because it balances speed and accuracy well.\n",
        "\n",
        "**sparse_categorical_crossentropy**\n",
        "\n",
        "   1.  This is used when labels are integer-encoded (e.g., 0, 1, 2, 3).\n",
        "   2.  If labels were one-hot encoded (e.g., [0,1,0,0]), we would use categorical_crossentropy.\n",
        "\n",
        "**Working**\n",
        "1.  Measures the difference between predicted class probabilities and actual class labels.\n",
        "2.  Encourages the model to assign higher probabilities to the correct class.\n",
        "\n",
        "**Metrics**\n",
        "1.  The model will track accuracy during training and evaluation.\n",
        "  \n",
        "  **Accuracy= Correct prediction / Total prediction**\n",
        "\n",
        "2.  Useful for classification problems where classes are balanced."
      ],
      "metadata": {
        "id": "PQihUWQHB91w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',  # Use sparse_categorical_crossentropy\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "RWCsyjr7FIQS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forward Pass:**\n",
        "The model makes predictions on train_dataset.\n",
        "\n",
        "**Loss Calculation:**\n",
        "Compares predictions with actual labels using sparse_categorical_crossentropy.\n",
        "\n",
        "**Backward Pass (Gradient Descent Update):**\n",
        "The Adam optimizer adjusts weights to minimize loss.\n",
        "\n",
        "**Repeat for All Samples:**\n",
        "This happens for every batch in the dataset.\n",
        "\n",
        "**End of One Epoch:**\n",
        "Once all samples are processed, one epoch is completed.\n",
        "Next Epoch:\n",
        "The model learns further with updated weights.\n"
      ],
      "metadata": {
        "id": "zS0hrh2EE86P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "          epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYWQYx0XQPIt",
        "outputId": "14b163d9-9106-4fde-c8fe-2154ebbdac7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7s/step - accuracy: 0.5022 - loss: 3.4714\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 362ms/step - accuracy: 0.8764 - loss: 0.3804\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 365ms/step - accuracy: 0.9379 - loss: 0.1829\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 363ms/step - accuracy: 0.9696 - loss: 0.0925\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 362ms/step - accuracy: 0.9690 - loss: 0.0956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c89db6d7bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_road_condition(class_index):\n",
        "  if class_index == 0:\n",
        "    return 'bump'\n",
        "  elif class_index == 1:\n",
        "    return 'crack'\n",
        "  elif class_index == 2:\n",
        "    return 'potholes'\n",
        "  elif class_index == 3:\n",
        "    return 'road'\n",
        "  else:\n",
        "    return 'unknown'\n",
        "\n",
        "predicted_class = predict_image(\"/content/drive/MyDrive/Data_set/Data/road/Augusta9c.jpg\")\n",
        "road_condition = get_road_condition(predicted_class)\n",
        "print(f\"The predicted road condition is: {road_condition}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2sZukWwQkDD",
        "outputId": "d3ae847a-d004-4984-ae02-d53852597d12"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "The predicted road condition is: road\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1MpTk-4OD6ExDNp-7MNbWBfCMintF33R4",
      "authorship_tag": "ABX9TyO7Xtuu9fFrWyxjdOsyU6+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}